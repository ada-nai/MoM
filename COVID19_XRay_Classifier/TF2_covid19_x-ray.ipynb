{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2LXxkYjIhEvh",
    "outputId": "aab9172f-c565-40bd-8b43-b76408effac1"
   },
   "outputs": [],
   "source": [
    "#IPython display\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(tf.__version__) \n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pKYifNzISEIx",
    "outputId": "6b6cae55-f123-4a3d-e848-8e1a53b93016"
   },
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "root_dir = Path.cwd()\n",
    "PATH = str(root_dir / 'generated_dataset')\n",
    "data_dir = pathlib.Path(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uvFcvAybuV_j",
    "outputId": "e87d46af-0c93-459b-d843-5a06e865169f"
   },
   "source": [
    "### Visualise and Preprocess Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ES6gNpJOhTOF",
    "outputId": "7b1e1eda-d533-433c-d316-45c00f503f8f"
   },
   "outputs": [],
   "source": [
    "# Check image count\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "omHoT_EuheHP",
    "outputId": "8324ff76-f569-4b62-e738-8324afa76c06"
   },
   "outputs": [],
   "source": [
    "# Extract target labels\n",
    "class_names = np.array([item.name for item in data_dir.glob('*')])\n",
    "list_labels = list(class_names)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJlR5MdzKuyc"
   },
   "outputs": [],
   "source": [
    "# View sample image\n",
    "normal = list(data_dir.glob('normal/*'))\n",
    "for image_path in normal[:1]:\n",
    "  print(image_path)\n",
    "  check_img = Image.open(str(image_path))\n",
    "  display.display(check_img)\n",
    "  w,h = check_img.size\n",
    "  print(\"original dimensions:{}x{}\".format(w,h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8VAec1eLjzQ"
   },
   "outputs": [],
   "source": [
    "# Use tf.data.Dataset to create a TF dataset in the file paths\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "type(list_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert file paths to (image, label) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUny99NQOw0M"
   },
   "outputs": [],
   "source": [
    "# Break the path to components\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(file_path, sep = os.path.sep )\n",
    "  #observe that the second last component is the name of the class\n",
    "  return parts[-2] == class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwQ_AG66R0GB"
   },
   "outputs": [],
   "source": [
    "# Decoding image to tensor and resize\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH  = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def decode_img(img):\n",
    "  #convert the image to a 3D tensor\n",
    "  img = tf.image.decode_jpeg(img, channels = 3)\n",
    "  #Use `convert_image_dtype` to convert to floats in the [0, 1] range\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnOyDnTfQe45"
   },
   "outputs": [],
   "source": [
    "# Finally club the desired operations\n",
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  #load the data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1j5FRgbdS_F7"
   },
   "outputs": [],
   "source": [
    "# TF map the above function to apply transformations to all samples in the dataset\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "gHSXJuP1UNlc",
    "outputId": "0d695636-1f98-42f4-a88d-fb65a0bed20d"
   },
   "outputs": [],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label:\", label.numpy())\n",
    "    print(type(label))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle-Repeat practice of samples (Refer: https://www.tensorflow.org/tutorials/load_data/images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat(count=1)\n",
    "\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PB2T5iIGF3ti"
   },
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(labeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJRrNHIkHDhE"
   },
   "outputs": [],
   "source": [
    "# Plot a batch\n",
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for n in range(16):\n",
    "      ax = plt.subplot(4,4,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      title = plt.title(class_names[label_batch[n]==1][0].title())\n",
    "      plt.setp(title, color = 'y')  \n",
    "      plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "RZw0CDvBJ5LG",
    "outputId": "82e27c2c-9188-40b9-8659-f9406b8e570f"
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vUcEyye_2d-U",
    "outputId": "29fad680-ec94-4f01-bb7f-c65233ee6b11"
   },
   "outputs": [],
   "source": [
    "# check the number of elements in the dataset\n",
    "# we have grouped the samples into batches so `cardinality` will consider the number of batches\n",
    "num_elements = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-TiXECL7TnH"
   },
   "outputs": [],
   "source": [
    "# perform train/validation split using take/split\n",
    "val_size = int(.1 * num_elements)\n",
    "val_ds = train_ds.take(val_size)\n",
    "train_ds = train_ds.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vamp8GCkvHse"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvtlrq9l7LQE"
   },
   "outputs": [],
   "source": [
    "# create base (no-brainer) model\n",
    "cd_model = Sequential([\n",
    "    Conv2D(8, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9896vdIOgXI"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cd_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "ZilRj0IoOlil",
    "outputId": "e0b87fb8-7508-4437-df5e-63436de657e2"
   },
   "outputs": [],
   "source": [
    "# check the model summary\n",
    "cd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "I0lF4ViROnhE",
    "outputId": "06ada2dd-0f92-4516-b6f7-e1a4446f7e08"
   },
   "outputs": [],
   "source": [
    "# finally fit the model\n",
    "epochs = 3\n",
    "history = cd_model.fit_generator(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data = val_ds,\n",
    "    verbose = 1,\n",
    "    initial_epoch = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "acc_fig = plt.figure(figsize=(6, 6))\n",
    "acc_ax = acc_fig.add_subplot()\n",
    "acc_ax.tick_params(colors='y')\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy', color = 'yellow')\n",
    "plt.show()\n",
    "\n",
    "loss_fig = plt.figure(figsize= (6, 6))\n",
    "loss_ax = loss_fig.add_subplot()\n",
    "loss_ax.tick_params(color= 'y')\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss', color = 'y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Model can be used to evaluate on images\n",
    "- Model can be tweaked, given better quality data (numerous enhancements/pathways possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF2_data_dogs&cats.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python3_homl",
   "language": "python",
   "name": "python3_homl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
